{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "L8kbFRoYj3BI",
        "jyowUsuDJFrk",
        "qBn6tAjx39E7"
      ],
      "authorship_tag": "ABX9TyNLCnosx/ko5i21qU5fNOeU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giordanovitale/Prado-Museum-CNN/blob/main/Prado_Artists.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   [Data Augmentation Techniques](https://medium.com/ymedialabs-innovation/data-augmentation-techniques-in-cnn-using-tensorflow-371ae43d5be9#8be0)\n",
        "2.   [Model Architectures](https://medium.com/@navarai/unveiling-the-diversity-a-comprehensive-guide-to-types-of-cnn-architectures-9d70da0b4521)\n",
        "3. [EfficientNet](https://towardsdatascience.com/complete-architectural-details-of-all-efficientnet-models-5fd5b736142)"
      ],
      "metadata": {
        "id": "WbjcyTneoQAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Source: https://www.kaggle.com/datasets/maparla/prado-museum-pictures"
      ],
      "metadata": {
        "id": "wzU4x8i_tk_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0 - Load the necessary libraries"
      ],
      "metadata": {
        "id": "o8R_We7Bjw9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install visualkeras"
      ],
      "metadata": {
        "id": "jGdZM9PWK_Yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "7FrmpviCjilL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import polars as pl\n",
        "\n",
        "import tqdm\n",
        "import os\n",
        "import requests\n",
        "\n",
        "from multiprocessing import cpu_count\n",
        "from multiprocessing.pool import ThreadPool\n",
        "import visualkeras as vk\n",
        "\n",
        "from scipy.optimize import fsolve\n",
        "from math import exp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.layers import Layer\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, \\\n",
        "    AveragePooling2D, BatchNormalization, ReLU, PReLU, ZeroPadding2D, \\\n",
        "    GlobalAveragePooling2D, Input, DepthwiseConv2D, Add, Activation, Lambda, RandomFlip, \\\n",
        "    Rescaling, RandomContrast, RandomZoom, RandomRotation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input as resnet_v2_preproccessing\n",
        "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input as efficientnet_preproccessing\n",
        "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B3\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input as vgg_preproccessing\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocessing\n",
        "\n",
        "# Get rid of the extra stuff that gets downloaded\n",
        "!rm -rf sample_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = (224,224,3)"
      ],
      "metadata": {
        "id": "O4u7vtjkI7bk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Helper Functions"
      ],
      "metadata": {
        "id": "L8kbFRoYj3BI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_url(args):\n",
        "    \"\"\"\n",
        "    Downloads a file from an url\n",
        "    :param args: Tuple containing the url and filename\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    url, filename = args[0], args[1]\n",
        "    try:\n",
        "      r = requests.get(url)\n",
        "      if r.status_code != 404:\n",
        "        with open(filename, \"wb\") as f:\n",
        "          f.write(r.content)\n",
        "\n",
        "    except Exception as e:\n",
        "      print(\"Exception in download_url():\", e)"
      ],
      "metadata": {
        "id": "OYyBBIO-jvgM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_parallel(args):\n",
        "    \"\"\"\n",
        "    Downloads urls in parallel\n",
        "    :param args: List of tuples containing the url and filename\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    cpus = cpu_count()\n",
        "    threadpool = ThreadPool(cpus)\n",
        "    with tqdm.tqdm(total=len(args), desc=\"Downloading images\") as pbar:\n",
        "        for _ in threadpool.imap_unordered(download_url, args):\n",
        "            pbar.update(1)\n",
        "    threadpool.close()\n",
        "    threadpool.join()"
      ],
      "metadata": {
        "id": "6lOeid62TQSE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Load the dataset using Kaggle API"
      ],
      "metadata": {
        "id": "MaMrNaJvoe2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "My Username and Key have been secreted. Replace `userdata.get('KAGGLE_USERNAME')` and `userdata.get('KAGGLE_KEY')`with your username and key, respectively."
      ],
      "metadata": {
        "id": "wZrGs5uD2s0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"KAGGLE_USERNAME\"] = \"userdata.get('KAGGLE_USERNAME')\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"userdata.get('KAGGLE_KEY')\"\n",
        "!kaggle datasets download maparla/prado-museum-pictures -f prado.csv\n",
        "!unzip prado.csv.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBj68-vEvZLa",
        "outputId": "4a40bea7-5ae9-4f8c-b933-8a4294b65bd8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/maparla/prado-museum-pictures\n",
            "License(s): MIT\n",
            "prado.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  prado.csv.zip\n",
            "replace prado.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the dataframe from the unzipepd csv file."
      ],
      "metadata": {
        "id": "RZ4NWN4a26ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(os.path.join(\"prado.csv\"))"
      ],
      "metadata": {
        "id": "FRAesYqqwHCr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since no target class has been defined from the project assignment, I have to decide it. After a careful inspection of the columns, I found out that the more suitable ones are `author` and `technical_sheet_tecnica`. The latter seems more intriguing as it has more observations, thus being more suitable to big data algorithms."
      ],
      "metadata": {
        "id": "d60cuROa2-o1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['author'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKYs7m-XwOyB",
        "outputId": "f441ad4e-9d91-4c6f-f5dd-94acd095c2d1"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "author\n",
              "Anónimo                                                                       2698\n",
              "Goya y Lucientes, Francisco de                                                1080\n",
              "Bayeu y Subías, Francisco                                                      446\n",
              "Haes, Carlos de                                                                326\n",
              "Pizarro y Librado, Cecilio                                                     290\n",
              "                                                                              ... \n",
              "Malombra, Pietro                                                                 1\n",
              "Taller de Bellini, Giovanni                                                      1\n",
              "Mattioli, Ludovico -Dibujante- (Autor de la obra original: Cignani, Carlo)       1\n",
              "Ricci, Marco                                                                     1\n",
              "García, Sergio                                                                   1\n",
              "Name: count, Length: 2560, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['technical_sheet_tecnica'].value_counts().sort_values(ascending=False)[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD4-MW-bwPga",
        "outputId": "15f34df9-309d-4242-f7ef-e76c6c0bda4b"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception in download_url(): [Errno 2] No such file or directory: 'data/pencil/59825391-c4b9-4f84-8d6f-413fa045a3ea.jpg'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "technical_sheet_tecnica\n",
              "Óleo                    4156\n",
              "Acuñación               1118\n",
              "Esculpido                550\n",
              "Lápiz compuesto          476\n",
              "Clarión; Lápiz negro     396\n",
              "Albúmina                 395\n",
              "Sanguina                 372\n",
              "Lápiz                    259\n",
              "Lápiz negro              237\n",
              "Pluma; Tinta parda       214\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reduce the data set by keeping observations belonging to the 4 classes of interest only."
      ],
      "metadata": {
        "id": "RaNVQhcOcjAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['technical_sheet_tecnica'].isin(['Óleo',\n",
        "                                            'Acuñación',\n",
        "                                            'Esculpido',\n",
        "                                            'Lápiz compuesto'])]"
      ],
      "metadata": {
        "id": "JjRARJodH5or"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B467V520Iwcn",
        "outputId": "ade3207b-4d2c-4c2d-86fd-c08dc99ef0b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6300, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to obtain the JPGs images, we need to start from the given URL column `work_image_url`."
      ],
      "metadata": {
        "id": "0iHqoZHs4btw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['work_id'] = df['work_image_url'].apply(lambda x: x.split('/')[-1])"
      ],
      "metadata": {
        "id": "bvORo-571oOX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the folders into which the images will be stored, according to their respective class."
      ],
      "metadata": {
        "id": "GO_mspTpBiTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The important columns are:\n",
        "`['work_image_url', 'work_id', 'technical_sheet_tecnica']`"
      ],
      "metadata": {
        "id": "FC_ZTuARczzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "NvXIGlFrRsRR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "esp_techniques = ['Óleo', 'Acuñación', 'Esculpido', 'Lápiz compuesto']\n",
        "eng_techniques = ['oil', 'minting', 'sculpture', 'pencil']"
      ],
      "metadata": {
        "id": "0MzHBZFvTgpP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rm -rf data"
      ],
      "metadata": {
        "id": "95J0G6lWUtRU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for technique in eng_techniques:\n",
        "  !mkdir -p data/$technique"
      ],
      "metadata": {
        "id": "dUdTNYO1RzSa"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir model_logs"
      ],
      "metadata": {
        "id": "1i5NdKk6dNVq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mJAjz_Hfczwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BF5ZPrAEeEHL"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "05d-eS5ynl5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_list = list()\n",
        "\n",
        "for esp_technique, eng_technique in zip(esp_techniques, eng_techniques):\n",
        "\n",
        "  image_urls = list(df['work_image_url'].loc[df['technical_sheet_tecnica'] == esp_technique])\n",
        "  image_names = list(df['work_id'].loc[df['technical_sheet_tecnica'] == esp_technique])\n",
        "  image_names = [f\"data/{eng_technique}/\" + fn for fn in image_names]\n",
        "\n",
        "  for url, fn in zip(image_urls, image_names):\n",
        "    download_list.append((url, fn))"
      ],
      "metadata": {
        "id": "LgleWlJtoExf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mI9BfgmV9S9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(download_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbWz_pknorCZ",
        "outputId": "e762ca34-9391-46a0-fa12-d6aba06b3008"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6300"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_parallel(download_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFc2YbyFosxg",
        "outputId": "2482bb73-b580-431d-c268-9472a00254e8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading images: 100%|██████████| 6300/6300 [2:03:55<00:00,  1.18s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class Imbalance"
      ],
      "metadata": {
        "id": "Z_MTwn-YQ37H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#class_weights"
      ],
      "metadata": {
        "id": "McYkNoNiMZ40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_oils = df.loc[df['technical_sheet_tecnica']=='Óleo'].shape[0]\n",
        "num_mintings = df.loc[df['technical_sheet_tecnica']=='Acuñación'].shape[0]\n",
        "num_sculptures = df.loc[df['technical_sheet_tecnica']=='Esculpido'].shape[0]\n",
        "num_pencils = df.loc[df['technical_sheet_tecnica']=='Lápiz compuesto'].shape[0]\n",
        "\n",
        "num_total = df.shape[0]"
      ],
      "metadata": {
        "id": "Ds6y2fbTMz9w"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = {\n",
        "    0: num_oils/num_total,\n",
        "    1: num_mintings/num_total,\n",
        "    2: num_sculptures/num_total,\n",
        "    3: num_pencils/num_total\n",
        "}\n",
        "\n",
        "class_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDE6xgiyMCSn",
        "outputId": "c667ddbd-1fed-4411-87e1-eba421b7e450"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.6596825396825396,\n",
              " 1: 0.17746031746031746,\n",
              " 2: 0.0873015873015873,\n",
              " 3: 0.07555555555555556}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Temporarily use loaded data and mount"
      ],
      "metadata": {
        "id": "_XcEZWRU7j8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"/content/drive/MyDrive/AMD\")\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drTVncya7sQf",
        "outputId": "14d356cf-5c9f-45ec-d7da-1faa560e9705"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "data  model_logs  Prado-Artists.ipynb  prado.csv  prado.csv.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, test_ds = tf.keras.utils.image_dataset_from_directory('/content/drive/MyDrive/AMD/data',\n",
        "                                                                label_mode='int',\n",
        "                                                                color_mode='rgb',\n",
        "                                                                batch_size=32,\n",
        "                                                                image_size=(224, 224),\n",
        "                                                                shuffle=True,\n",
        "                                                                seed=42,\n",
        "                                                                validation_split=0.2,\n",
        "                                                                subset='both',\n",
        "                                                                labels='inferred',\n",
        "                                                                class_names=['oil', 'minting', 'sculpture', 'pencil'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c6x1p8SEav6",
        "outputId": "4226308e-a818-4f28-dcaf-14c52c032738"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5935 files belonging to 4 classes.\n",
            "Using 4748 files for training.\n",
            "Using 1187 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "22noSiIqKM3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/tutorials/images/data_augmentation"
      ],
      "metadata": {
        "id": "dhN1PODLEN6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the link above:\n",
        "\n",
        "> Note: Data augmentation is inactive at test time so input images will only be augmented during calls to Model.fit (not Model.evaluate or Model.predict).\n",
        "\n"
      ],
      "metadata": {
        "id": "eoZ2PpzPGKbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 4"
      ],
      "metadata": {
        "id": "-lewV5opGf1U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***"
      ],
      "metadata": {
        "id": "hNe5_9epKOcJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 - Model 1: ZFNet"
      ],
      "metadata": {
        "id": "jyowUsuDJFrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zfnet = Sequential([\n",
        "\n",
        "    # Preprocessing layers\n",
        "    tf.keras.layers.Rescaling(1./255),\n",
        "    tf.keras.layers.RandomFlip(mode='horizontal_and_vertical',\n",
        "                               input_shape=INPUT_SHAPE,\n",
        "                               name='Random_Horizontal_And_Vertical_Flip'),\n",
        "    tf.keras.layers.RandomRotation(factor=0.2,\n",
        "                                   input_shape=INPUT_SHAPE,\n",
        "                                   name='Random_Rotation'),\n",
        "    tf.keras.layers.RandomContrast(factor=0.2,\n",
        "                                   input_shape=INPUT_SHAPE,\n",
        "                                   name='Random_Contrast'),\n",
        "    tf.keras.layers.RandomZoom(height_factor=(-0.2, -0.1),\n",
        "                               input_shape=INPUT_SHAPE,\n",
        "                               name='Random_Zoom'),\n",
        "\n",
        "\n",
        "    # 1st convolutional block\n",
        "    Conv2D(filters=48,\n",
        "           kernel_size=(7,7),\n",
        "           strides=(2,2),\n",
        "           padding='valid',\n",
        "           activation=None,\n",
        "           name='Conv_1'),\n",
        "    ReLU(name='ReLU_1'),\n",
        "    MaxPooling2D(pool_size=(3,3),\n",
        "                 strides=(2,2),\n",
        "                 padding='valid',\n",
        "                 name='Max_Pooling_1'),\n",
        "\n",
        "    # 2nd convolutional block\n",
        "    Conv2D(filters=128,\n",
        "           kernel_size=(3,3),\n",
        "           strides=(2,2),\n",
        "           padding='valid',\n",
        "           activation=None,\n",
        "           name='Conv_2'),\n",
        "    ReLU(name='ReLU_2'),\n",
        "    MaxPooling2D(pool_size=(3,3),\n",
        "                 strides=(2,2),\n",
        "                 padding='valid',\n",
        "                 name='Max_Pooling_2'),\n",
        "\n",
        "    # 3rd convolutional block\n",
        "    Conv2D(filters=192,\n",
        "           kernel_size=(3,3),\n",
        "           strides=(1,1),\n",
        "           padding='valid',\n",
        "           activation=None,\n",
        "           name='Conv_3.1'),\n",
        "    ReLU(name='ReLU_3.1'),\n",
        "    Conv2D(filters=384,\n",
        "           kernel_size=(3,3),\n",
        "           strides=(1,1),\n",
        "           padding='valid',\n",
        "           activation=None,\n",
        "           name='Conv_3.2'),\n",
        "    ReLU(name='ReLU_3.2'),\n",
        "    Conv2D(filters=192,\n",
        "           kernel_size=(3,3),\n",
        "           strides=(1,1),\n",
        "           padding='valid',\n",
        "           activation=None,\n",
        "           name='Conv_3.3'),\n",
        "    ReLU(name='ReLU_3.3'),\n",
        "    MaxPooling2D(pool_size=(3,3),\n",
        "                 strides=(2,2),\n",
        "                 padding='valid',\n",
        "                 name='Max_Pooling_3'),\n",
        "\n",
        "    # Flatten Layer\n",
        "    Flatten(name='Flatten'),\n",
        "\n",
        "    # 1st Dense Layer\n",
        "    Dense(units=256,\n",
        "          activation='relu',\n",
        "          name='Dense_1'),\n",
        "\n",
        "    # 2nd Dense Layer\n",
        "    Dense(units=256,\n",
        "          activation='relu',\n",
        "          name='Dense_2'),\n",
        "\n",
        "    # 3rd Dense Layer\n",
        "    Dense(units=num_classes,\n",
        "          activation='softmax',\n",
        "          name=\"Output\")\n",
        "],\n",
        "    name='ZFNet')"
      ],
      "metadata": {
        "id": "dPhZ7yTvo9TT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zfnet.build(input_shape=(None, *INPUT_SHAPE))\n",
        "zfnet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87NX1WgU35jU",
        "outputId": "0838766f-6938-4a88-ca61-98027fd77bd4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"ZFNet\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_3 (Rescaling)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " Random_Horizontal_And_Vert  (None, 224, 224, 3)       0         \n",
            " ical_Flip (RandomFlip)                                          \n",
            "                                                                 \n",
            " Random_Rotation (RandomRot  (None, 224, 224, 3)       0         \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " Random_Contrast (RandomCon  (None, 224, 224, 3)       0         \n",
            " trast)                                                          \n",
            "                                                                 \n",
            " Random_Zoom (RandomZoom)    (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " Conv_1 (Conv2D)             (None, 109, 109, 48)      7104      \n",
            "                                                                 \n",
            " ReLU_1 (ReLU)               (None, 109, 109, 48)      0         \n",
            "                                                                 \n",
            " Max_Pooling_1 (MaxPooling2  (None, 54, 54, 48)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " Conv_2 (Conv2D)             (None, 26, 26, 128)       55424     \n",
            "                                                                 \n",
            " ReLU_2 (ReLU)               (None, 26, 26, 128)       0         \n",
            "                                                                 \n",
            " Max_Pooling_2 (MaxPooling2  (None, 12, 12, 128)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " Conv_3.1 (Conv2D)           (None, 10, 10, 192)       221376    \n",
            "                                                                 \n",
            " ReLU_3.1 (ReLU)             (None, 10, 10, 192)       0         \n",
            "                                                                 \n",
            " Conv_3.2 (Conv2D)           (None, 8, 8, 384)         663936    \n",
            "                                                                 \n",
            " ReLU_3.2 (ReLU)             (None, 8, 8, 384)         0         \n",
            "                                                                 \n",
            " Conv_3.3 (Conv2D)           (None, 6, 6, 192)         663744    \n",
            "                                                                 \n",
            " ReLU_3.3 (ReLU)             (None, 6, 6, 192)         0         \n",
            "                                                                 \n",
            " Max_Pooling_3 (MaxPooling2  (None, 2, 2, 192)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " Flatten (Flatten)           (None, 768)               0         \n",
            "                                                                 \n",
            " Dense_1 (Dense)             (None, 256)               196864    \n",
            "                                                                 \n",
            " Dense_2 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " Output (Dense)              (None, 4)                 1028      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1875268 (7.15 MB)\n",
            "Trainable params: 1875268 (7.15 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model compiling."
      ],
      "metadata": {
        "id": "54ThNT8aK3Yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zfnet.compile(loss=SparseCategoricalCrossentropy(),\n",
        "              optimizer=Adam(),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "jNQQIG-yJ_Dc"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create csv logger to save the results in case it stops."
      ],
      "metadata": {
        "id": "_rE5T_4bK5Qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zfnet_csv_logger = CSVLogger(\"/content/model_logs/zfnet.log\")"
      ],
      "metadata": {
        "id": "Z4iXDMXhKZ6E"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model."
      ],
      "metadata": {
        "id": "nvReb7aZK9Oe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zfnet_history = zfnet.fit(train_ds,\n",
        "                          epochs=30,\n",
        "                          steps_per_epoch=len(train_ds),\n",
        "                          validation_data=test_ds,\n",
        "                          validation_steps=len(test_ds),\n",
        "                          class_weight=class_weights,\n",
        "                          callbacks=zfnet_csv_logger)"
      ],
      "metadata": {
        "id": "Ft1tUhCWK_j7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 - Model 2: My Own Proposal"
      ],
      "metadata": {
        "id": "GGyQtP-3MAB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gionet = Sequential([\n",
        "\n",
        "    # Preprocessing layers\n",
        "    tf.keras.layers.Rescaling(1./255),\n",
        "    tf.keras.layers.RandomFlip(mode='horizontal_and_vertical',\n",
        "                               input_shape=INPUT_SHAPE,\n",
        "                               name='Random_Horizontal_And_Vertical_Flip'),\n",
        "    tf.keras.layers.RandomRotation(factor=0.2,\n",
        "                                   input_shape=INPUT_SHAPE,\n",
        "                                   name='Random_Rotation'),\n",
        "    tf.keras.layers.RandomContrast(factor=0.2,\n",
        "                                   input_shape=INPUT_SHAPE,\n",
        "                                   name='Random_Contrast'),\n",
        "    tf.keras.layers.RandomZoom(height_factor=(-0.2, -0.1),\n",
        "                               input_shape=INPUT_SHAPE,\n",
        "                               name='Random_Zoom'),\n",
        "    tf.keras.layers.Lambda(function=tf.image.per_image_standardization,\n",
        "                           name=\"Per_image_standardisation\"),\n",
        "\n",
        "\n",
        "    # 1st convolutional block\n",
        "    Conv2D(filters=224,\n",
        "           kernel_size=(3,3),\n",
        "           strides=(2,2),\n",
        "           padding='same',\n",
        "           activation=None,\n",
        "           name='Conv_1'),\n",
        "    ReLU(name='ReLU_1'),\n",
        "    AveragePooling2D(pool_size=(3,3),\n",
        "                     strides=(2,2),\n",
        "                     padding='same',\n",
        "                     name='Avg_Pooling_1'),\n",
        "\n",
        "\n",
        "    # 2nd convolutional block\n",
        "    Conv2D(filters=112,\n",
        "           kernel_size=(3,3),\n",
        "           strides=(2,2),\n",
        "           padding='same',\n",
        "           activation=None,\n",
        "           name='Conv_2'),\n",
        "    ReLU(name='ReLU_2'),\n",
        "    AveragePooling2D(pool_size=(3,3),\n",
        "                     strides=(2,2),\n",
        "                     padding='same',\n",
        "                     name='Avg_Pooling_2'),\n",
        "\n",
        "    # 3rd convolutional block\n",
        "    Conv2D(filters=56,\n",
        "           kernel_size=(3,3),\n",
        "           strides=(2,2),\n",
        "           padding='same',\n",
        "           activation=None,\n",
        "           name='Conv_3'),\n",
        "    ReLU(name='ReLU_3'),\n",
        "    AveragePooling2D(pool_size=(3,3),\n",
        "                     strides=(2,2),\n",
        "                     padding='same',\n",
        "                     name='Avg_Pooling_3'),\n",
        "\n",
        "    # 4th convolutional block\n",
        "    Conv2D(filters=28,\n",
        "           kernel_size=(5,5),\n",
        "           strides=(1,1),\n",
        "           padding='same',\n",
        "           activation=None,\n",
        "           name='Conv_4.1'),\n",
        "    ReLU(name='ReLU_4.1'),\n",
        "    Conv2D(filters=28,\n",
        "           kernel_size=(5,5),\n",
        "           strides=(1,1),\n",
        "           padding='same',\n",
        "           activation=None,\n",
        "           name='Conv_4.2'),\n",
        "    ReLU(name='ReLU_4.2'),\n",
        "    AveragePooling2D(pool_size=(3,3),\n",
        "                     strides=(2,2),\n",
        "                     padding='valid',\n",
        "                     name='Avg_Pooling_4'),\n",
        "\n",
        "    # Flatten Layer\n",
        "    Flatten(name='Flatten'),\n",
        "\n",
        "    # 1st Dense Layer\n",
        "    Dense(units=64,\n",
        "          activation='relu',\n",
        "          name='Dense_1'),\n",
        "\n",
        "    # 2nd Dense Layer\n",
        "    Dense(units=num_classes,\n",
        "          activation='softmax',\n",
        "          name=\"Output\")\n",
        "],\n",
        "    name='GioNet')"
      ],
      "metadata": {
        "id": "kTEd89JBEqyz"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gionet.build(input_shape=(None, *INPUT_SHAPE))\n",
        "gionet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYPt3WdIv2B2",
        "outputId": "62f3f5bb-64bd-4bb9-d3e0-46d533d98df4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"GioNet\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_3 (Rescaling)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " Random_Horizontal_And_Vert  (None, 224, 224, 3)       0         \n",
            " ical_Flip (RandomFlip)                                          \n",
            "                                                                 \n",
            " Random_Rotation (RandomRot  (None, 224, 224, 3)       0         \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " Random_Contrast (RandomCon  (None, 224, 224, 3)       0         \n",
            " trast)                                                          \n",
            "                                                                 \n",
            " Random_Zoom (RandomZoom)    (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " Per_image_standardisation   (None, 224, 224, 3)       0         \n",
            " (Lambda)                                                        \n",
            "                                                                 \n",
            " Conv_1 (Conv2D)             (None, 112, 112, 224)     6272      \n",
            "                                                                 \n",
            " ReLU_1 (ReLU)               (None, 112, 112, 224)     0         \n",
            "                                                                 \n",
            " Avg_Pooling_1 (AveragePool  (None, 56, 56, 224)       0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " Conv_2 (Conv2D)             (None, 28, 28, 112)       225904    \n",
            "                                                                 \n",
            " ReLU_2 (ReLU)               (None, 28, 28, 112)       0         \n",
            "                                                                 \n",
            " Avg_Pooling_2 (AveragePool  (None, 14, 14, 112)       0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " Conv_3 (Conv2D)             (None, 7, 7, 56)          56504     \n",
            "                                                                 \n",
            " ReLU_3 (ReLU)               (None, 7, 7, 56)          0         \n",
            "                                                                 \n",
            " Avg_Pooling_3 (AveragePool  (None, 4, 4, 56)          0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " Conv_4.1 (Conv2D)           (None, 4, 4, 28)          39228     \n",
            "                                                                 \n",
            " ReLU_4.1 (ReLU)             (None, 4, 4, 28)          0         \n",
            "                                                                 \n",
            " Conv_4.2 (Conv2D)           (None, 4, 4, 28)          19628     \n",
            "                                                                 \n",
            " ReLU_4.2 (ReLU)             (None, 4, 4, 28)          0         \n",
            "                                                                 \n",
            " Avg_Pooling_4 (AveragePool  (None, 1, 1, 28)          0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " Flatten (Flatten)           (None, 28)                0         \n",
            "                                                                 \n",
            " Dense_1 (Dense)             (None, 64)                1856      \n",
            "                                                                 \n",
            " Output (Dense)              (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 349652 (1.33 MB)\n",
            "Trainable params: 349652 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model"
      ],
      "metadata": {
        "id": "l4KZU8Bfv7u1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gionet.compile(loss=SparseCategoricalCrossentropy(),\n",
        "               optimizer=Adam(),\n",
        "               metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "si8p-R4Sv9U9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CSV logger in case it stops."
      ],
      "metadata": {
        "id": "Uwf3LuWowV-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gionet_csv_logger = CSVLogger(\"/content/drive/MyDrive/AMD/model_logs/gionet.log\")"
      ],
      "metadata": {
        "id": "x9ZpkVvdwXuF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model."
      ],
      "metadata": {
        "id": "dggLpZbpxFpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gionet_history = gionet.fit(train_ds,\n",
        "                            epochs=30,\n",
        "                            steps_per_epoch=len(train_ds),\n",
        "                            validation_data=test_ds,\n",
        "                            validation_steps=len(test_ds),\n",
        "                            class_weight=class_weights,\n",
        "                            callbacks=gionet_csv_logger)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "U1Lpc0ylxHDW",
        "outputId": "b1492ba7-3665-4a05-9f8d-bc145262c593"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "  2/149 [..............................] - ETA: 55:53 - loss: 0.6947 - accuracy: 0.2969      "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-fe9256b86e75>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m gionet_history = gionet.fit(train_ds,\n\u001b[0m\u001b[1;32m      2\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "color_map = defaultdict(dict)\n",
        "\n",
        "# Assign the same color to all the preprocessing steps\n",
        "color_map[Rescaling][\"fill\"] = \"#3785CD\"\n",
        "color_map[RandomFlip][\"fill\"] = \"#3785CD\"\n",
        "color_map[RandomRotation][\"fill\"] = \"#3785CD\"\n",
        "color_map[RandomContrast][\"fill\"] = \"#3785CD\"\n",
        "color_map[RandomZoom][\"fill\"] = \"#3785CD\"\n",
        "color_map[Lambda][\"fill\"] = \"#3785CD\"\n",
        "\n",
        "\n",
        "color_map[AveragePooling2D][\"fill\"] = \"#25bdf0\"\n",
        "color_map[Dense][\"fill\"] = \"#78ba41\"\n",
        "\n",
        "vk.layered_view(gionet,\n",
        "                legend=True,\n",
        "                scale_xy=2,\n",
        "                scale_z=.01,\n",
        "                type_ignore=[Rescaling, RandomFlip, RandomRotation, RandomContrast,\n",
        "                RandomZoom, Lambda],\n",
        "                color_map=color_map\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "uikTx7D1L1Ob",
        "outputId": "122226ef-7c36-426e-f477-e508853479e6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGBA size=561x335>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 - Third Model"
      ],
      "metadata": {
        "id": "Pb6lEGuzKGD6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "88yjLF43KJNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the folders"
      ],
      "metadata": {
        "id": "qBn6tAjx39E7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define source and destination paths\n",
        "source_path = '/content/data'\n",
        "destination_path = '/content/drive/My Drive/AMD/data'\n",
        "\n",
        "# Copy the folder to Google Drive\n",
        "shutil.copytree(source_path, destination_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "57W_ZcG2g6n6",
        "outputId": "198f9b5b-5d33-49f5-dcdb-fd373e362a14"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/AMD/data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}